# Innovation Grant Accomplishments

While the goal of this grant is to create a digital assistant skill, a lot more has gone into the project than just the coding of the skill. We [recorded what the skill](https://vimeo.com/323543288) is able to do for your viewing pleasure.

## Design Decisions

We decided to use the python programming language for this skill. The reason being the intersection of languages supported in google cloud functions and amazon lambda is node.js, python, and go. We chose python over node.js because the latest stable version available in google is node.js 6 and does not support async await. The language used to write skills is not very important nor does it affect the goals of this project.

We chose to start with Amazon alexa since DTS seemingly has a better working relationship with Amazon. Employees at AGRC had prior experience with alexa and own devices. We thought this would lead to more rapid progress.

## Onboarding

Bringing developers into the Amazon web services and alexa ecosystem as a Utah.gov employee was very time consuming. Alexa and AWS are separate entities within Amazon as a whole and different authentication methods are required for both services. In cooperation with DTS Engineering and Security we

1. Connected AWS to Utah.gov LDAP
   - Developers can create lambda serverless functions that handle the requests from alexa skills as well as access CloudWatch to view logs generated by lambda functions
1. Organized separate Amazon developer accounts by agency
   - Developers can create alexa skills.
1. Defined the minimal permissions required for service accounts to develop a functioning skill
   - Developers can use the Amazon Skills Kit CLI and aws CLI to automate repetitive tasks
1. Proposed a system to maintain the lifecycle of service account credentials
   - Since there is no option for two factor authentication, alternative approaches were required

## Productivity

The project we created is organized and structured to reduce the time to productivity. Reducing the amount of time and decisions necessary to set up a project was a goal. Since every developer working on a skill can and should have their own isolated environment, we developed a custom CLI tool that automates repetitive developer tasks within these isolated environments.

1. Generating the required files for each developer
   - unique `.ask/config` and `skill.json` files
1. Switching between using cloud and local resources for skill development
   - There are limitations in the environments so it is neccessary to switch often
1. Tagging cloud resources following DTS guidelines
1. Generating/expanding machine learning sample data from a terse syntax
1. Generating repeatable test data specific to an alexa skill and it's functionality

## Development

We built a functioning skill. As we built the project we kept much more in mind than only the skill. We focused heavily on the development feedback cycle.

Amazon recommends testing your skill with cloud resources, but that incurs two types of cost.

1. Cloud compute time for every request generated by the skill costs money
1. Developer time
   - Idle while waiting for their updates to deploy to the cloud
   - Increased debug time using CloudWatch and print/log statements

To improve this, we used existing technologies to allow developer machines to directly respond to alexa skill requests. Removing the requirement for lambda reduces development cost by enabling instantaneous updates from modifications to skill logic, compile time errors are found immediately, and feature rich debugging experiences are available - like pause and explore debugging.

## Side effects

During the creation of this skill we reviewed what data and api's were available to make this skill possible. This skill looked at using data from three agencies.

1. AGRC
   - api.mapserv.utah.gov
   - gis spatial requests
1. Utah State Legislature
   - glen.le.utah.gov
   - legislator and session information
1. Elections
   - vote.utah.gov
   - voter and voting information

The AGRC api worked great for this skill and required no modifications. Geocoding the device address and searching for policital districts is very simple. The documentation is satisfactory.

The legislature api handled the alexa use case very well. The documentation is satisfactory. The developers are willing to improve their api. They added ~6 new endpoints after we had some discussions.

One area that falls short and could be improved is the purpose of the data is optimized to be displayed on websites. This creates a challenge as we transition to supporting voice. It is difficult to use the data without sounding like a robot.

The vote api is complicated and had no documentation. It appeared to be a private api built specifically for the vote website. The developers are willing to improve the api but we did not have time to create a plan and approach them with the details.

## Ongoing

We could meet with legislators in the house and senate to present on new possibilities created by this skill. Currently, there is a form submitted to le.utah.gov with legislator information. If we could influence that form, this skill and others would benefit. Since screens are more and more common on digital assistant devices, short video clips could be presented to users. The audio coud be played on devices without a screen.

We could create api reports for agencies so they can understand what is missing, lacking, or requiring improvement in their api coverage. This would fit into Mike's api creation initiative as it would give ideas to agencies on what to build.

While exploring the opportunities for this skill, generated a script similar to a playwright of how users could interact. This script could be complimented/enhanced by software designed for conversation. I believe it would be in the best interest of DTS and the agencies it supports to purchase a software to assist in the creation of voice skills.

1. [Invocable](https://www.invocable.com)
1. [voiceflow](https://www.getvoiceflow.com/)
